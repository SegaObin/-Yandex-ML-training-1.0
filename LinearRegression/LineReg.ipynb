{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c82871",
   "metadata": {},
   "source": [
    "# Линейная регрессия\n",
    "## Самописный класс MyLineReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115d23f8-c309-43c6-bf49-739789fd160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81600908-be72-48c1-9c4e-83b63549d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg:\n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, metric=None, reg=None, l1_coef=0, l2_coef=0, sgd_sample=0.1, random_state=42):\n",
    "        \"\"\"Initialize the linear regression model parameters.\"\"\"\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.best_score = None\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, Y, verbose=False):\n",
    "        \"\"\"Fit the linear regression model to the training data.\"\"\"\n",
    "        random.seed(self.random_state)\n",
    "\n",
    "        Y = Y.to_numpy()\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        N = X.shape[0]\n",
    "        self.weights = np.ones(X.shape[1]) * 0.01\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "\n",
    "            if self.sgd_sample is None:\n",
    "                sample_size = N\n",
    "            elif isinstance(self.sgd_sample, int):\n",
    "                sample_size = self.sgd_sample\n",
    "            else:\n",
    "                sample_size = int(N * self.sgd_sample)\n",
    "\n",
    "            sample_row_idx = random.sample(range(N), sample_size)\n",
    "            batch_X = X[sample_row_idx]\n",
    "            batch_Y = Y[sample_row_idx]\n",
    "\n",
    "            if callable(self.learning_rate):\n",
    "                current_learning_rate = self.learning_rate(i + 1)\n",
    "            else:\n",
    "                current_learning_rate = self.learning_rate\n",
    "\n",
    "            Y_pred = self._predict(batch_X)\n",
    "            error = self._calculate_error(batch_Y, Y_pred)\n",
    "\n",
    "            self.best_score = error\n",
    "            gradient = self._calculate_gradient(\n",
    "                batch_X, batch_Y, Y_pred, sample_size)\n",
    "\n",
    "            self.weights -= current_learning_rate * gradient\n",
    "\n",
    "            if verbose and i % verbose == 0:\n",
    "                print(\n",
    "                    f\"Iteration {i} | Loss: {self._calculate_loss(batch_Y, Y_pred)} | Metric: {error}\")\n",
    "\n",
    "    def _calculate_error(self, Y, Y_pred):\n",
    "        \"\"\"Calculate the error metric based on the provided type.\"\"\"\n",
    "        if self.metric == 'mse':\n",
    "            return ((Y_pred - Y) ** 2).mean()\n",
    "        elif self.metric == 'mae':\n",
    "            return np.mean(np.abs(Y_pred - Y))\n",
    "        elif self.metric == 'rmse':\n",
    "            return (((Y_pred - Y) ** 2).mean()) ** 0.5\n",
    "        elif self.metric == 'mape':\n",
    "            return ((np.abs((Y_pred - Y) / Y)) * 100).mean()\n",
    "        elif self.metric == 'r2':\n",
    "            ss_res = ((Y_pred - Y) ** 2).sum()\n",
    "            ss_tot = ((Y - Y.mean()) ** 2).sum()\n",
    "            return 1 - ss_res / ss_tot\n",
    "        else:\n",
    "            return ((Y_pred - Y) ** 2).mean()\n",
    "\n",
    "    def _calculate_loss(self, Y, Y_pred):\n",
    "        \"\"\"Calculate loss for the current predictions.\"\"\"\n",
    "        base_loss = ((Y_pred - Y) ** 2).mean()\n",
    "        if self.reg == 'l1':\n",
    "            return base_loss + self.l1_coef * np.sum(np.abs(self.weights))\n",
    "        elif self.reg == 'l2':\n",
    "            return base_loss + self.l2_coef * np.sum(self.weights ** 2)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return base_loss + self.l1_coef * np.sum(np.abs(self.weights)) + self.l2_coef * np.sum(self.weights ** 2)\n",
    "        else:\n",
    "            return base_loss\n",
    "\n",
    "    def _calculate_gradient(self, X, Y, Y_pred, N):\n",
    "        \"\"\"Calculate the gradient for weight update.\"\"\"\n",
    "        error_term = Y_pred - Y\n",
    "        base_gradient = (2 / N) * X.T.dot(error_term)\n",
    "\n",
    "        if self.reg == 'l1':\n",
    "            return base_gradient + self.l1_coef * np.sign(self.weights)\n",
    "        elif self.reg == 'l2':\n",
    "            return base_gradient + self.l2_coef * (2 * self.weights)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return base_gradient + self.l1_coef * np.sign(self.weights) + self.l2_coef * (2 * self.weights)\n",
    "        else:\n",
    "            return base_gradient\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"Return the predicted output for given features.\"\"\"\n",
    "        return X.dot(self.weights)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions for the input data.\"\"\"\n",
    "        X = X.to_numpy()\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return self._predict(X)\n",
    "\n",
    "    def get_coef(self):\n",
    "        \"\"\"Return the model coefficients.\"\"\"\n",
    "        return self.weights[1:]\n",
    "\n",
    "    def get_best_score(self):\n",
    "        \"\"\"Return the best score observed during training.\"\"\"\n",
    "        return self.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa14816",
   "metadata": {},
   "source": [
    "## Сравнение самописного класса со встроенным в библиотеку scikit-learn\n",
    "Для сравнения используем датасет fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0cd900-3794-470b-be71-15991a352787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "california_housing_data = fetch_california_housing(as_frame=True)\n",
    "california_housing_df = california_housing_data.frame\n",
    "california_housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a636670-565f-4198-9231-407116dd29a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры обучающей выборки: (16512, 8), (16512,)\n",
      "Размеры тестовой выборки: (4128, 8), (4128,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = california_housing_df.drop(columns=['MedHouseVal'])\n",
    "y = california_housing_df['MedHouseVal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размеры обучающей выборки: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Размеры тестовой выборки: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(data=scaler.fit_transform(X_train))\n",
    "X_test_scaled = pd.DataFrame(data=scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c79b1242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка предсказания модели из библиотеки sklearn: 0.5558915986952444\n"
     ]
    }
   ],
   "source": [
    "sklearn_regression = LinearRegression()\n",
    "sklearn_regression.fit(X_train_scaled, y_train)\n",
    "sklearn_prediction = sklearn_regression.predict(X_test_scaled)\n",
    "print(\n",
    "    f'Ошибка предсказания модели из библиотеки sklearn: {mse(sklearn_prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428d1a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Loss: 5.504583989238672 | Metric: 5.504583989238672\n",
      "Iteration 100 | Loss: 0.5608681110697722 | Metric: 0.5608681110697722\n",
      "Iteration 200 | Loss: 0.5502441789164211 | Metric: 0.5502441789164211\n",
      "Iteration 300 | Loss: 0.5226595309423533 | Metric: 0.5226595309423533\n",
      "Iteration 400 | Loss: 0.5778929925640858 | Metric: 0.5778929925640858\n",
      "Iteration 500 | Loss: 0.5401883627853428 | Metric: 0.5401883627853428\n",
      "Iteration 600 | Loss: 0.5537862868180132 | Metric: 0.5537862868180132\n",
      "Iteration 700 | Loss: 0.5101366901601977 | Metric: 0.5101366901601977\n",
      "Iteration 800 | Loss: 0.5084999224794219 | Metric: 0.5084999224794219\n",
      "Ошибка предсказания самописной модели: 0.5698712523981718\n"
     ]
    }
   ],
   "source": [
    "my_model = MyLineReg(n_iter=900, learning_rate= lambda iter: 0.85 * (0.85 ** iter))\n",
    "my_model.fit(X_train_scaled, y_train, verbose=100, )\n",
    "my_model_prediction = my_model.predict(X_test_scaled)\n",
    "print(\n",
    "    f\"Ошибка предсказания самописной модели: {my_model._calculate_error(y_test, my_model_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4788f0",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "Самописная модель не иедальна. Она дает результат чуть хуже чем стандартная модель из библиотеки. Так же проблемой модели является то, что для того, чтобы она работала необходимо масштабировать данные (это несложно добавляется в класс, но модель создана для понимания работы линейной регрессии \"под капотом\", поэтому не считаю это необходимым).\n",
    "\n",
    "Разница в метриках модлелей достаточно мала, чтобы утвердить, что самописная модель написана правильно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
